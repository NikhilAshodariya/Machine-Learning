{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent for Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescent:\n",
    "    \n",
    "    def __init__(self,x,ydata,learningRate=0.01):\n",
    "        self.learningRate=learningRate\n",
    "        self._checkNumberOfElement=2 #it means that 2 errors values will be checked for stopping  if they are same then stop\n",
    "        self._error=[] #used to store the error\n",
    "        self._numberOfIterationHappened=0  #total number of iterations \n",
    "        \n",
    "        self._maximumErrorValueStored=100 #it is the maximum number of error that will be stored used to avoid memory problem\n",
    "        self.x=x\n",
    "        self.x.insert(0, 'cool', [1]*len(self.x[self.x.columns[0]])) #inserting x0=1\n",
    "        \n",
    "        self.y=ydata\n",
    "        self._beta=[0]*(len(self.x.columns)) # initalizing all beta's to zeros\n",
    "    \n",
    "    \n",
    "    #x=[[1,2,3,4...],[3,2,3...],[1,23,3...]]\n",
    "    #below function is used in case if x and y are two big such that the inital error will be infinite\n",
    "    def _preWorking(self,x):\n",
    "        x_mean=np.divide(np.sum(x),len(x))\n",
    "        return x-x_mean\n",
    "        \n",
    "    def _betaMulX(self):\n",
    "        temp=[]\n",
    "        for i in range(0,len(self.x.columns)):\n",
    "            colname=self.x.columns[i]\n",
    "            temp.append(np.multiply([self._beta[i]],self.x[colname]))\n",
    "        return temp\n",
    "        \n",
    "    \n",
    "    def _calculateYHat(self):\n",
    "        #y=b0*x0+b1*x1+b2*x2+b3*x3.....\n",
    "        modifiedX=self._betaMulX()\n",
    "        #modifiedX=[[beta0*x0],[beta1*x1],[beta2*x2],[beta3*x3]...]\n",
    "        temp=0\n",
    "        yhat=[]\n",
    "        for j in range(0,len(self.y)):\n",
    "            for i in range(0,len(modifiedX)):\n",
    "                temp=temp+modifiedX[i][j]\n",
    "            yhat.append(temp)\n",
    "        return yhat\n",
    "                \n",
    "    def _checkConverage(self):\n",
    "        yhat=self._calculateYHat()\n",
    "        error=np.sum(np.square(np.subtract(yhat,np.asarray(self.y))))/len(self.y)\n",
    "        self._error.append(error)\n",
    "        \n",
    "        temp=self._error[-self._checkNumberOfElement:]\n",
    "        \n",
    "        if self._checkIfAllSame(temp)==False  or self._numberOfIterationHappened<self._checkNumberOfElement:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    def _checkIfAllSame(self,temp):\n",
    "        return all(x==temp[0] for x in temp)\n",
    "        \n",
    "    \n",
    "    def _gradientDescent(self,learningRate=0.001):\n",
    "        #np.subtract(self._calculateYHat(),self.y)\n",
    "        \n",
    "        while self._checkConverage()==False:\n",
    "            self._numberOfIterationHappened=self._numberOfIterationHappened+1\n",
    "#             print(\"alogrithm running\")\n",
    "            for i in range(0,len(self._beta)):\n",
    "                self.abcdef=np.asarray(self._calculateYHat())\n",
    "                self.temp=np.subtract(np.asmatrix(self.abcdef).transpose(),np.asarray(self.y))\n",
    "                self.temp=np.multiply(np.asarray(self.x[self.x.columns[i]]),np.asarray(self.temp).transpose())\n",
    "                self.temp1=learningRate*np.sum(self.temp)/len(self.y)\n",
    "                self._beta[i]=self._beta[i]-self.temp1\n",
    "                if self._numberOfIterationHappened>=self._maximumErrorValueStored:\n",
    "                    self._error=self._error[-self._checkNumberOfElement:]\n",
    "            \n",
    "            \n",
    "    \n",
    "    def fit(self):\n",
    "        self._gradientDescent(self.learningRate)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"cdata.csv\")\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=df[['x']]\n",
    "y=df[['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.4)\n",
    "\n",
    "X_mean=np.divide(np.sum(X_train),len(X_train))\n",
    "Modified_X_train=X_train-X_mean #incase if the dataset values are too large\n",
    "\n",
    "y_mean=np.divide(np.sum(y_train),len(y_train))\n",
    "Modified_y_train=y_train-y_mean #incase if the dataset values are too large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=GradientDescent(Modified_X_train,Modified_y_train) \n",
    "model=GradientDescent(X,y) #since the dataset is small so the overfitting is allowed for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._calculateYHat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
